Kubernetes - k8s - B1 - Part 1

Kubernetes (K8s) is an open-source container orchestration system 
or platform or COE (container orchestration engine) for automating 
deployment, scaling, and management of containerized applications.

Why we need k8s? What problem does Kubernetes solve? 
What are some drawbacks of using docker to manage an application? 

1. Docker runs on single host - Docker is a containerisation platform
   that provides basic solution for managing the application lifecycle
   through containers on a single host. If this host goes down, we 
   need a manual intervention to restart the host, thereby affecting
   the availability of the application. 

2. Docker Containers are Ephemeral in nature - Docker DO NOT provide 
   out of the box support for auto-healing, i.e. when a container stops
   or is having an issue, we need to restart the container manually.

3. Docker lacks enterprise level features such as health-checks, 
   auto-scaling, etc.

To overcome these drawbacks of a containers we use kubernetes.

These are some of the enterprise level support for applications offered 
by kubernetes:

1. High Availability: Kubernetes provides built-in support for high 
   availability by enabling the deployment of multiple copies (replicas) of 
   applications across multiple nodes in a cluster. It ensures that applications
   remain available and accessible even in the event of node failures or other 
   disruptions.

2. Auto-scaling: Kubernetes supports horizontal auto-scaling, allowing applications
   to automatically scale up or down based on resource utilization metrics such as 
   CPU usage or custom metrics. This ensures that applications can handle varying 
   levels of workload efficiently without manual intervention.

3. Rolling Updates and Rollbacks: Kubernetes supports rolling updates and rollbacks 
   for applications, allowing seamless updates and version rollbacks without downtime. 
   This feature ensures minimal disruption to services during updates and provides a 
   mechanism to revert to a previous version in case of issues.

4. Resource Quotas and Limits: Kubernetes allows administrators to define resource 
   quotas and limits for applications, namespaces, and individual containers. 
   This helps in resource management, preventing resource contention and ensuring fair 
   allocation of resources among different applications.

5. Security: Kubernetes provides several security features to ensure the confidentiality, 
   integrity, and availability of applications and data. This includes built-in support 
   for network policies, pod security policies, role-based access control (RBAC), 
   secrets management, and encryption of data in transit and at rest.

6. Monitoring and Logging: Kubernetes integrates with various monitoring and logging 
   solutions to provide visibility into the health, performance, and logs of applications 
   running in the cluster. Popular monitoring and logging solutions include Prometheus, 
   Grafana, Elasticsearch, and Fluentd.

7. Pro-active health monitoring and auto-healing using health check probes such as 
   readiness probe, liveness probe, startup probe. Using auto-healing feature k8s will
   restart the pod if a pod is down/stopped.

8. Service Discovery and Load Balancing: Kubernetes offers built-in service discovery and 
   load balancing capabilities to route traffic to applications running in the cluster. 
   It automatically assigns DNS names and IP addresses to services and distributes incoming 
   requests across multiple instances of an application.

9. Storage Orchestration: Kubernetes provides storage orchestration features to dynamically 
   provision and manage storage resources for applications. It supports various storage 
   backends, including local storage, network-attached storage (NAS), and cloud storage 
   providers, and allows for the dynamic provisioning of persistent volumes (PVs) and 
   persistent volume claims (PVCs).

10. Multi-tenancy: Kubernetes supports multi-tenancy, allowing multiple teams or users to 
    share a single Kubernetes cluster while maintaining isolation and resource segregation.
    This is achieved through the use of namespaces, RBAC, and network policies to enforce 
    security and resource isolation between tenants.

11. Extensibility and Ecosystem: Kubernetes is highly extensible and offers a rich ecosystem 
    of plugins, extensions, and third-party integrations to enhance its functionality. 
    This includes support for custom resource definitions (CRDs), operators, custom controllers, 
    and integration with various cloud providers, CI/CD tools, and application frameworks.

Thanks to these capabilities of Kubernetes, the occurrence of application downtime and the 
need for manual interventions in managing applications are minimized.


Basic Components of k8s:

pod - 
A basic deployable resource in kubernetes is called a Pod.
It is the smallest deployable unit and is actually a wrapper around containers.
A pod usually contains a single container but can have more than one container.

service - 
 - Service discovery [using labels and selectors],
 - load balancing 
 - Expose application to the outside using service types:
 a. clusterIP Mode - default mode, allows access within the k8s cluster
 b. NodePort Mode - allows access to the app within your organisation
 c. LoadBalancer Mode - allows access to the application from outside world
ingress -  manages routing using host or path based routing instead of ip address

configMap - configuration data of applications like database connection url, etc
secrets - store sensitive informations: credentails in base64 encoding
volumes - to persist data across pod restarts so as to maintain the state of 
          the deployed application

Architecture of k8s:

The two main components of a Kubernetes (k8s) cluster are 
the Control Plane (also known as the Master node) and 
the Data Plane Worker nodes (also known as the Worker or Minion nodes).

Master node / Control Plane processes are:
-> API server - heart of k8s cluster - cluster gateway - all requests are first 
   received by API server
-> Etcd - brain of k8s - has all info about the k8s cluster in key-value pairs 
-> Scheduler - monitors and based on info in Etcd, it decides the nodes for
   pods to be scheduled and forwards the request to kubelet for pod creation
   Scheduler checks which node has enough resource for pod creation and forwards
   the request to that node.
-> controller manager (CM) - runs in loop, monitors for state changes, 
   maintains desired state of the k8s cluster - it will inform scheduler
   if pod is down and if there is a mismatch in desired state and actual state
   of the k8s cluster.
-> cloud controller manager - The Cloud Controller Manager is responsible for 
   interacting with the cloud provider's APIs to manage resources like virtual 
   machines, load balancers, and storage.
   The Cloud Controller Manager (CCM) is specific to cloud providers such as AWS, GCP
   or Azure. While Kubernetes provides the framework and interfaces for implementing 
   the Cloud Controller Manager, each cloud provider typically implements its own 
   version to interact with its specific infrastructure.

Data Plane / Worker node processes are:
-> container runtime process: ex: containerd, CRIO - it runs and manages containers 
-> kubelet - creates pods, assigning resources to the pod
-> kube proxy - decides where to forward the access request for a resource
    Ex: database access - handles networking aspect of the pods in k8s cluster
